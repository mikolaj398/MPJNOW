Analiza num_hidden_layers - loss: 
          0         1        2         3
0  1.000000  0.225871  0.90000  0.001000
1  0.225871  1.000000  0.30713  0.109694
2  0.900000  0.307130  1.00000  0.001000
3  0.001000  0.109694  0.00100  1.000000

Analiza num_hidden_layers - recall: 
          0         1         2         3
0  1.000000  0.896267  0.132924  0.001000
1  0.896267  1.000000  0.455715  0.001124
2  0.132924  0.455715  1.000000  0.109694
3  0.001000  0.001124  0.109694  1.000000

Analiza num_hidden_layers - precision: 
          0         1         2         3
0  1.000000  0.799047  0.017062  0.900000
1  0.799047  1.000000  0.001000  0.799047
2  0.017062  0.001000  1.000000  0.017062
3  0.900000  0.799047  0.017062  1.000000

Analiza num_hidden_layers - f1: 
          0         1         2         3
0  1.000000  0.799047  0.225871  0.009860
1  0.799047  1.000000  0.028569  0.109694
2  0.225871  0.028569  1.000000  0.001000
3  0.009860  0.109694  0.001000  1.000000

Analiza num_hidden_layers - accuracy: 
          0         1         2         3
0  1.000000  0.799047  0.225871  0.009860
1  0.799047  1.000000  0.028569  0.109694
2  0.225871  0.028569  1.000000  0.001000
3  0.009860  0.109694  0.001000  1.000000




Analiza num_attention_heads - loss: 
          0      1         2         3
0  1.000000  0.900  0.900000  0.005517
1  0.900000  1.000  0.900000  0.001000
2  0.900000  0.900  1.000000  0.005517
3  0.005517  0.001  0.005517  1.000000

Analiza num_attention_heads - recall: 
         0        1        2        3
0  1.00000  0.90000  0.04628  0.00100
1  0.90000  1.00000  0.04628  0.00100
2  0.04628  0.04628  1.00000  0.30713
3  0.00100  0.00100  0.30713  1.00000

Analiza num_attention_heads - precision: 
          0         1         2         3
0  1.000000  0.799047  0.900000  0.028569
1  0.799047  1.000000  0.900000  0.001572
2  0.900000  0.900000  1.000000  0.005517
3  0.028569  0.001572  0.005517  1.000000

Analiza num_attention_heads - f1: 
          0         1         2         3
0  1.000000  0.799047  0.507386  0.001572
1  0.799047  1.000000  0.109694  0.001000
2  0.507386  0.109694  1.000000  0.109694
3  0.001572  0.001000  0.109694  1.000000

Analiza num_attention_heads - accuracy: 
          0         1         2         3
0  1.000000  0.799047  0.507386  0.001572
1  0.799047  1.000000  0.109694  0.001000
2  0.507386  0.109694  1.000000  0.109694
3  0.001572  0.001000  0.109694  1.000000




Analiza hidden_act - loss: 
          0         1         2
0  1.000000  0.019949  0.900000
1  0.019949  1.000000  0.019949
2  0.900000  0.019949  1.000000

Analiza hidden_act - recall: 
         0         1         2
0  1.00000  0.010210  0.900000
1  0.01021  1.000000  0.004967
2  0.90000  0.004967  1.000000

Analiza hidden_act - precision: 
          0         1         2
0  1.000000  0.019949  0.373279
1  0.019949  1.000000  0.373279
2  0.373279  0.373279  1.000000

Analiza hidden_act - f1: 
          0         1         2
0  1.000000  0.002297  0.900000
1  0.002297  1.000000  0.002297
2  0.900000  0.002297  1.000000

Analiza hidden_act - accuracy: 
          0         1         2
0  1.000000  0.002297  0.900000
1  0.002297  1.000000  0.002297
2  0.900000  0.002297  1.000000




Analiza attention_probs_dropout_prob - loss: 
          0         1         2         3
0  1.000000  0.005517  0.028569  0.017062
1  0.005517  1.000000  0.900000  0.900000
2  0.028569  0.900000  1.000000  0.900000
3  0.017062  0.900000  0.900000  1.000000

Analiza attention_probs_dropout_prob - recall: 
          0         1         2         3
0  1.000000  0.072567  0.002990  0.001000
1  0.072567  1.000000  0.701825  0.160247
2  0.002990  0.701825  1.000000  0.701825
3  0.001000  0.160247  0.701825  1.000000

Analiza attention_probs_dropout_prob - precision: 
          0         1         2         3
0  1.000000  0.307130  0.900000  0.507386
1  0.307130  1.000000  0.507386  0.009860
2  0.900000  0.507386  1.000000  0.307130
3  0.507386  0.009860  0.307130  1.000000

Analiza attention_probs_dropout_prob - f1: 
          0         1         2         3
0  1.000000  0.001000  0.001000  0.225871
1  0.001000  1.000000  0.900000  0.109694
2  0.001000  0.900000  1.000000  0.072567
3  0.225871  0.109694  0.072567  1.000000

Analiza attention_probs_dropout_prob - accuracy: 
          0        1         2         3
0  1.000000  0.00100  0.001000  0.225871
1  0.001000  1.00000  0.900000  0.046280
2  0.001000  0.90000  1.000000  0.160247
3  0.225871  0.04628  0.160247  1.000000




